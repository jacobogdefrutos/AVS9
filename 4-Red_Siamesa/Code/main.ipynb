{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications import VGG19\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam,SGD\n",
    "from utils import to_grayscale_then_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110160_OD_INF_SANO.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110160_OD_NAS_SANO.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110160_OD_SUP_SANO.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110160_OD_TEM_SANO.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2581150_OD_INF_CMV.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>781208_OI_TEM_SANO.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>795004_OI_INF_POSTNER.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>795004_OI_NAS_POSTNER.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>795004_OI_SUP_POSTNER.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>795004_OI_TEM_POSTNER.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name Label\n",
       "0       110160_OD_INF_SANO.jpg     0\n",
       "1       110160_OD_NAS_SANO.jpg     0\n",
       "2       110160_OD_SUP_SANO.jpg     0\n",
       "3       110160_OD_TEM_SANO.jpg     0\n",
       "4       2581150_OD_INF_CMV.jpg     1\n",
       "..                         ...   ...\n",
       "123     781208_OI_TEM_SANO.jpg     0\n",
       "124  795004_OI_INF_POSTNER.jpg     1\n",
       "125  795004_OI_NAS_POSTNER.jpg     1\n",
       "126  795004_OI_SUP_POSTNER.jpg     1\n",
       "127  795004_OI_TEM_POSTNER.jpg     1\n",
       "\n",
       "[128 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_train_b_csv='..\\Iris_train_basic_seg_list.csv'\n",
    "df_train_basic= pd.read_csv(file_train_b_csv)\n",
    "datagen=ImageDataGenerator(rescale=1./255.,preprocessing_function=to_grayscale_then_rgb)\n",
    "df_train_basic['Label']= df_train_basic['Label'].astype(str)\n",
    "df_train_basic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_val_csv='..\\Iris_val_basic_seg_list.csv'\n",
    "df_val= pd.read_csv(file_val_csv)\n",
    "df_val['Label']= df_val['Label'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 128 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df_train_basic,\n",
    "    directory=r\"D:\\Users\\jacob\\AVS9\\Data\\saved_seg_class_images\\train_basic\",\n",
    "    x_col=\"Name\",\n",
    "    y_col=\"Label\",\n",
    "    batch_size=5,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224))#540,810\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df_val,\n",
    "    directory=r\"D:\\Users\\jacob\\AVS9\\Data\\saved_seg_class_images\\val\",\n",
    "    x_col=\"Name\",\n",
    "    y_col=\"Label\",\n",
    "    batch_size=5,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_test_csv='..\\Iris_test_seg_list.csv'\n",
    "df_test= pd.read_csv(file_test_csv)\n",
    "df_test['class_label']= df_test['class_label'].astype(str)\n",
    "df_test['label_OI']= df_test['label_OI'].astype(str)\n",
    "df_test['label_OD']= df_test['label_OD'].astype(str)\n",
    "test_generator_OI = datagen.flow_from_dataframe(\n",
    "    dataframe=df_test,\n",
    "    directory=r\"D:\\Users\\jacob\\AVS9\\Data\\saved_seg_class_images\\test\",\n",
    "    x_col=\"OI\",\n",
    "    y_col=\"label_OI\",\n",
    "    batch_size=2,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    "    target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import build_LeNet5\n",
    "input_shape=(224,224,1)\n",
    "model=build_LeNet5(input_shape)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=val_generator.n//val_generator.batch_size\n",
    "#STEP_SIZE_TEST=test_generator_OI.n//test_generator_OI.batch_size\n",
    "#model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 11s 297ms/step - loss: 0.7148 - accuracy: 0.4960 - val_loss: 0.6946 - val_accuracy: 0.3667\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 6s 255ms/step - loss: 0.6346 - accuracy: 0.7805 - val_loss: 0.7636 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 7s 292ms/step - loss: 0.4336 - accuracy: 0.8211 - val_loss: 0.8197 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 12s 460ms/step - loss: 0.1507 - accuracy: 0.9593 - val_loss: 2.1571 - val_accuracy: 0.4333\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 4s 178ms/step - loss: 0.0718 - accuracy: 0.9837 - val_loss: 1.4298 - val_accuracy: 0.4333\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 4s 153ms/step - loss: 0.0215 - accuracy: 0.9919 - val_loss: 1.9714 - val_accuracy: 0.4667\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 4s 166ms/step - loss: 0.0726 - accuracy: 0.9756 - val_loss: 1.8837 - val_accuracy: 0.4667\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.6364 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 4s 151ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.8387 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 7.7125e-04 - accuracy: 1.0000 - val_loss: 2.1313 - val_accuracy: 0.4667\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 4.9188e-04 - accuracy: 1.0000 - val_loss: 1.8346 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 7s 237ms/step - loss: 3.6000e-04 - accuracy: 1.0000 - val_loss: 2.3878 - val_accuracy: 0.4667\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 4s 141ms/step - loss: 2.6653e-04 - accuracy: 1.0000 - val_loss: 2.5002 - val_accuracy: 0.4333\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 4s 162ms/step - loss: 2.1722e-04 - accuracy: 1.0000 - val_loss: 2.3283 - val_accuracy: 0.4667\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 5s 182ms/step - loss: 1.7318e-04 - accuracy: 1.0000 - val_loss: 2.6157 - val_accuracy: 0.4333\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 4s 163ms/step - loss: 1.5111e-04 - accuracy: 1.0000 - val_loss: 2.6630 - val_accuracy: 0.4333\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 4s 168ms/step - loss: 1.2828e-04 - accuracy: 1.0000 - val_loss: 2.3837 - val_accuracy: 0.5000\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 1.1012e-04 - accuracy: 1.0000 - val_loss: 2.7608 - val_accuracy: 0.4333\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 4s 166ms/step - loss: 9.3924e-05 - accuracy: 1.0000 - val_loss: 2.6952 - val_accuracy: 0.4667\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 7.8690e-05 - accuracy: 1.0000 - val_loss: 2.5177 - val_accuracy: 0.4667\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(x=train_generator, steps_per_epoch=STEP_SIZE_TRAIN, validation_data=val_generator, \n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=20,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x=test_generator_OI,\n",
    "steps=STEP_SIZE_TEST)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Iris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
