{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F #de aqui podemos coger la funcion pairwise_distance para calcula la ecludian_distance\n",
    "from utils import get_loaders, ContrastiveLoss, train_fn, val_loss\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from lenet5 import LeNet5\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR= r'Data\\saved_test_clas_images\\train'\n",
    "VAL_DIR= r'Data\\saved_test_clas_images\\val'\n",
    "train_csv='Iris_train_seg_list.csv'\n",
    "val_csv='Iris_val_seg_list.csv'\n",
    "BATCH_SIZE= 2\n",
    "NUM_WORKERS=4\n",
    "NUM_EPOCHS=20\n",
    "IMAGE_HEIGHT=540\n",
    "IMAGE_WIDTH=810\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Epoch:  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Users\\jacob\\AVS9\\3-Red_Siamesa\\Code\\main_2.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/jacob/AVS9/3-Red_Siamesa/Code/main_2.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-------------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/jacob/AVS9/3-Red_Siamesa/Code/main_2.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m\"\u001b[39m, epoch)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Users/jacob/AVS9/3-Red_Siamesa/Code/main_2.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     train_loss,train_losses_list, counter\u001b[39m=\u001b[39m train_fn(train_loader,model,optimizer,loss_fn,device\u001b[39m=\u001b[39;49mDEVICE)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/jacob/AVS9/3-Red_Siamesa/Code/main_2.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     vall_loss,val_losses_list, counter\u001b[39m=\u001b[39m val_loss(val_loader,model,optimizer,loss_fn,device\u001b[39m=\u001b[39mDEVICE)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/jacob/AVS9/3-Red_Siamesa/Code/main_2.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m fig, axs \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m9\u001b[39m, \u001b[39m3\u001b[39m), sharey\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Users\\jacob\\AVS9\\3-Red_Siamesa\\Code\\utils.py:62\u001b[0m, in \u001b[0;36mtrain_fn\u001b[1;34m(loader, model, optimizer, loss_fn, device)\u001b[0m\n\u001b[0;32m     60\u001b[0m counter\u001b[39m=\u001b[39m []\n\u001b[0;32m     61\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m---> 62\u001b[0m \u001b[39mfor\u001b[39;00m i,sample \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39;49m(loader,\u001b[39m0\u001b[39;49m):\n\u001b[0;32m     63\u001b[0m     img_OI,img_OD, label \u001b[39m=\u001b[39msample\n\u001b[0;32m     64\u001b[0m     img_OI, img_OD, label \u001b[39m=\u001b[39m img_OI\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice), img_OD\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice), label\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice)\n",
      "File \u001b[1;32md:\\Users\\jacob\\Anaconda3\\envs\\Iris\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    440\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32md:\\Users\\jacob\\Anaconda3\\envs\\Iris\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Users\\jacob\\Anaconda3\\envs\\Iris\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1042\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1035\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1043\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32md:\\Users\\jacob\\Anaconda3\\envs\\Iris\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32md:\\Users\\jacob\\Anaconda3\\envs\\Iris\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32md:\\Users\\jacob\\Anaconda3\\envs\\Iris\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32md:\\Users\\jacob\\Anaconda3\\envs\\Iris\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Users\\jacob\\Anaconda3\\envs\\Iris\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define the torchvision image transforms\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((IMAGE_HEIGHT,IMAGE_WIDTH),antialias=True),\n",
    "    transforms.Normalize(mean=[0.0], std=[1.0])\n",
    "])\n",
    "train_loader, val_loader= get_loaders(train_csv,val_csv,TRAIN_DIR,VAL_DIR,BATCH_SIZE,transform,NUM_WORKERS)\n",
    "loss_fn = ContrastiveLoss()\n",
    "model= LeNet5().to(device=DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "for epoch in range(0, NUM_EPOCHS):\n",
    "    print(\"-------------------------------------\")\n",
    "    print(\"Epoch: \", epoch)\n",
    "    train_loss,train_losses_list, counter= train_fn(train_loader,model,optimizer,loss_fn,device=DEVICE)\n",
    "    vall_loss,val_losses_list, counter= val_loss(val_loader,model,optimizer,loss_fn,device=DEVICE)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(9, 3), sharey=True)\n",
    "axs[0].plot(counter,train_losses_list)\n",
    "axs[1].plot(counter,val_losses_list)\n",
    "print(\"End of main\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Iris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
